{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbPMUJM4lAkn",
    "outputId": "ae1f4e5d-4ff7-4e8d-979d-dca72898b998",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-da1ef4fa55f7>:27: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv('/content/train_data.txt', sep=':::', header=None, names=['Movie', 'Title', 'Genre', 'Description'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      " Movie          0\n",
      "Title          0\n",
      "Genre          0\n",
      "Description    0\n",
      "dtype: int64\n",
      "\n",
      "Class Distribution:\n",
      "  drama           13613\n",
      " documentary     13096\n",
      " comedy           7447\n",
      " short            5073\n",
      " horror           2204\n",
      " thriller         1591\n",
      " action           1315\n",
      " western          1032\n",
      " reality-tv        884\n",
      " family            784\n",
      " adventure         775\n",
      " music             731\n",
      " romance           672\n",
      " sci-fi            647\n",
      " adult             590\n",
      " crime             505\n",
      " animation         498\n",
      " sport             432\n",
      " talk-show         391\n",
      " fantasy           323\n",
      " mystery           319\n",
      " musical           277\n",
      " biography         265\n",
      " history           243\n",
      " game-show         194\n",
      " news              181\n",
      " war               132\n",
      "Name: Genre, dtype: int64\n",
      "\n",
      "Number of empty documents: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      action        0.59      0.07      0.12       240\n",
      "       adult        0.89      0.07      0.13       110\n",
      "   adventure        0.67      0.04      0.07       165\n",
      "   animation        0.00      0.00      0.00        93\n",
      "   biography        0.00      0.00      0.00        54\n",
      "      comedy        0.51      0.42      0.46      1482\n",
      "       crime        0.00      0.00      0.00       119\n",
      " documentary        0.57      0.86      0.69      2600\n",
      "       drama        0.45      0.84      0.59      2649\n",
      "      family        0.00      0.00      0.00       157\n",
      "     fantasy        0.00      0.00      0.00        67\n",
      "   game-show        1.00      0.20      0.33        35\n",
      "     history        0.00      0.00      0.00        47\n",
      "      horror        0.68      0.31      0.42       459\n",
      "       music        0.70      0.05      0.09       147\n",
      "     musical        0.00      0.00      0.00        39\n",
      "     mystery        0.00      0.00      0.00        74\n",
      "        news        0.00      0.00      0.00        40\n",
      "  reality-tv        0.67      0.01      0.02       187\n",
      "     romance        0.00      0.00      0.00       139\n",
      "      sci-fi        0.86      0.05      0.09       130\n",
      "       short        0.60      0.09      0.16      1050\n",
      "       sport        0.75      0.07      0.12        89\n",
      "   talk-show        0.00      0.00      0.00        68\n",
      "    thriller        0.45      0.02      0.03       312\n",
      "         war        0.97      1.00      0.98      2785\n",
      "     western        0.98      0.55      0.70       202\n",
      "\n",
      "     accuracy                           0.61     13539\n",
      "    macro avg       0.42      0.17      0.19     13539\n",
      " weighted avg       0.61      0.61      0.55     13539\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  16    0    0    0    0   18    0   30  144    0    0    0    0    6\n",
      "     0    0    0    0    0    0    1    3    2    0    1   18    1]\n",
      " [   0    8    3    0    0   40    0   10   46    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    1    0    0    0    0    0]\n",
      " [   3    1    6    0    0   16    0   42   88    0    0    0    0    3\n",
      "     0    0    0    0    1    0    0    3    0    0    1    1    0]\n",
      " [   0    0    0    0    0   26    0   27   33    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    4    0    0    0    1    0]\n",
      " [   0    0    0    0    0    5    0   37   11    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    1    0]\n",
      " [   0    0    0    0    0  629    0  147  686    0    0    0    0    9\n",
      "     1    0    0    0    0    0    0    6    0    0    0    4    0]\n",
      " [   1    0    0    0    0   17    0   10   89    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    0    0    0    1    0    0]\n",
      " [   1    0    0    0    0   42    0 2248  262    0    0    0    0    4\n",
      "     0    0    0    0    0    0    0   13    0    0    1   29    0]\n",
      " [   2    0    0    0    0  104    0  271 2233    0    0    0    0    5\n",
      "     0    0    0    0    0    0    0   15    0    0    2   17    0]\n",
      " [   0    0    0    0    0   31    0   51   68    0    0    0    0    2\n",
      "     1    0    0    0    0    0    0    2    0    0    0    2    0]\n",
      " [   0    0    0    0    0    7    0   19   37    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    1    0    0    0    1    0]\n",
      " [   0    0    0    0    0    5    0   20    2    0    0    7    0    0\n",
      "     0    0    0    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0   33   13    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    1    0]\n",
      " [   0    0    0    0    0   41    0   41  230    0    0    0    0  141\n",
      "     0    0    0    0    0    0    0    5    0    0    0    1    0]\n",
      " [   0    0    0    0    0   11    0  118   10    0    0    0    0    0\n",
      "     7    0    0    0    0    0    0    1    0    0    0    0    0]\n",
      " [   0    0    0    0    0    8    0   16   14    0    0    0    0    0\n",
      "     1    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    4    0   12   55    0    0    0    0    3\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0   36    4    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0   49    0  117   18    0    0    0    0    0\n",
      "     0    0    0    0    2    0    0    0    0    0    0    1    0]\n",
      " [   0    0    0    0    0   18    0    9  112    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0    5    0   58   45    0    0    0    0    7\n",
      "     0    0    0    0    0    0    6    4    0    0    0    4    0]\n",
      " [   0    0    0    0    0  105    0  420  410    0    0    0    0    5\n",
      "     0    0    0    0    0    0    0   96    0    0    0   13    1]\n",
      " [   0    0    0    0    0    6    0   69    6    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    2    6    0    0    0    0]\n",
      " [   1    0    0    0    0    7    0   57    3    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   2    0    0    0    0   22    0   22  241    0    0    0    0   16\n",
      "     0    0    0    0    0    0    0    3    0    0    5    1    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0 2785    0]\n",
      " [   0    0    0    0    0   10    0    1   79    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    1  111]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "# Function to balance classes using oversampling\n",
    "def balance_classes(data, major_class, minority_classes, oversampler):\n",
    "    # Separate features and target variable\n",
    "    X = data['Description']\n",
    "    y = data['Genre']\n",
    "\n",
    "    # Initialize oversampler\n",
    "    oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "    # Upsample the minority classes\n",
    "    upsampled_data, upsampled_labels = oversampler.fit_resample(X.values.reshape(-1, 1), y)\n",
    "\n",
    "    # Convert the oversampled data and labels back to a DataFrame\n",
    "    upsampled_df = pd.DataFrame(upsampled_data, columns=['Description'])\n",
    "    upsampled_df['Genre'] = upsampled_labels\n",
    "\n",
    "    return upsampled_df\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('/content/train_data.txt', sep=':::', header=None, names=['Movie', 'Title', 'Genre', 'Description'])\n",
    "\n",
    "print(\"\\nMissing values:\\n\", data.isnull().sum())\n",
    "\n",
    "print(\"\\nClass Distribution:\\n\", data['Genre'].value_counts())\n",
    "\n",
    "# Check for empty documents\n",
    "empty_documents = data['Description'].apply(lambda x: len(str(x).split()) == 0)\n",
    "print(\"\\nNumber of empty documents:\", empty_documents.sum())\n",
    "\n",
    "# Drop empty documents\n",
    "data = data[~empty_documents]\n",
    "\n",
    "# Update the oversampling function call\n",
    "upsampled_data = balance_classes(data, 'drama', ['documentary'], RandomOverSampler())\n",
    "\n",
    "# Separate features and target variable in the upsampled data\n",
    "X_train_upsampled = upsampled_data['Description']\n",
    "y_train_upsampled = upsampled_data['Genre']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_upsampled, y_train_upsampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UHhRpXll3cP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
