{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd2b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6075fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      ",سوريا,399,http://www.adab.com/modules.php?name=Sh3er&doWhat=lsq&shid=399&start=0,قحطان بيرقدار 67162,http://www.adab.com/modules.php?name=Sh3er&doWhat=shqas&qid=67162&r=&rc=36,فصحى, والامر كل الامر انك غاءبه وانا هنا امشي علي طرق الدواءر‏ ان ابالغ في الانحناء لكي ازرع القنبلة,إنحناء السنبلة ..\n",
      ",مصر,10,http://www.adab.com/modules.php?name=Sh3er&doWhat=lsq&shid=10&start=0,فاروق جويدة 67594,http://www.adab.com/modules.php?name=Sh3er&doWhat=shqas&qid=67594&r=&rc=136,فصحى,عادت ايامك في خجل تذكرين كيف كانوا بالامس اية رءيا رسموها فلم تعش طويلا?\n",
      "None\n",
      ",العراق,498,http://www.adab.com/modules.php?name=Sh3er&doWhat=lsq&shid=498&start=0,معد الجبوري 76100,http://www.adab.com/modules.php?name=Sh3er&doWhat=shqas&qid=76100&r=&rc=27,فصحى,طاءري‏ في البءر مرمي‏ وازهاري‏ تحت العجله ‏ وانا وانت القادران علي الوصول ‏,هي بضعُ غيماتٍ ...\n",
      ",العراق,498,http://www.adab.com/modules.php?name=Sh3er&doWhat=lsq&shid=498&start=0,معد الجبوري 76100,http://www.adab.com/modules.php?name=Sh3er&doWhat=shqas&qid=76100&r=&rc=27,فصحى,طاءري‏ في البءر الذي خلفته‏ وراءي ‏,طرديَّةُ الخروج...\n",
      ",تونس,414,http://www.adab.com/modules.php?name=Sh3er&doWhat=lsq&shid=414&start=0,محمّد كمال السخيري 69285,http://www.adab.com/modules.php?name=Sh3er&doWhat=shqas&qid=69285&r=&rc=18,فصحى,كم اعشق الورد حين يزهر السوسن,أنـت الحيـاة ...\n"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "import codecs\n",
    "\n",
    "# Get raw text as string.\n",
    "with codecs.open(\"all_poems.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Get raw text as string.\n",
    "#with open(\"all_poems.csv\") as f:\n",
    "#    text = f.read()\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.Text(text)\n",
    "\n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    print(text_model.make_sentence())\n",
    "\n",
    "# Print three randomly-generated sentences of no more than 280 characters\n",
    "for i in range(3):\n",
    "    print(text_model.make_short_sentence(280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1969ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "يا ندي يا شذي يا رءي يا سماء واضواءه تحدي المخابء في كبرياء?\n",
      ",مصر,10,http://www.adab.com/modules.php?name=Sh3er&doWhat=lsq&shid=10&start=0,فاروق جويدة 67236,http://www.adab.com/modules.php?name=Sh3er&doWhat=shqas&qid=67236&r=&rc=98,فصحى,واخاف اشباح الشتاء واخاف ان القاك يوما في جسدين ماذا يتبقي من وجه جميل ,صَدِيقُ الوَهْم ..\n",
      "ليس الاسم حضنا ليس الحضن امراة اخذ شفتي منك هذه اليلة حيث يخرج طاءر الرغبة نحو سمت من السرخس ودوار الشمس?\n"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.Text(text)\n",
    "\n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    print(text_model.make_sentence())\n",
    "\n",
    "# Print three randomly-generated sentences of no more than 280 characters\n",
    "for i in range(3):\n",
    "    print(text_model.make_short_sentence(280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5ae8008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first round didn't even seem to follow recipe.\n",
      "red salmon gives a very quick and simple, and very easy.\n",
      "it freezes well if you are using frozen cranberries. if you can.\n",
      "be careful not to disturb them for christmas so am ill-equipped to modify to suit your family's tastes.\n",
      "this one is quick and easy and i think these would be great for lenten meals.\n",
      "i haven't tried it yet but only if i do not have time to share with some crusty french bread for dipping brats, i made them in a pita. it is so delicious, a co-worker came in an old-fashioned way, it is a very small batch.\n",
      "i used crunchy peanut butter and the crunch of the broth; and i can't eat it every year for my family fights over the top of rice is quite refreshing.\n",
      "it always brings compliments.\n"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "import codecs\n",
    "\n",
    "# Get raw text as string.\n",
    "with codecs.open(\"RAW_recipes.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Get raw text as string.\n",
    "#with open(\"all_poems.csv\") as f:\n",
    "#    text = f.read()\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.Text(text)\n",
    "\n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    print(text_model.make_sentence())\n",
    "\n",
    "# Print three randomly-generated sentences of no more than 280 characters\n",
    "for i in range(3):\n",
    "    print(text_model.make_short_sentence(280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bfc7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I had considered the prisoner a moment without pain.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Read the HTML file\n",
    "with open('pg98-images.html.utf8', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse HTML content and extract text\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text_content = ' '.join([p.text for p in soup.find_all('p')])  # Extract text from <p> tags, modify as needed\n",
    "\n",
    "# Preprocess the text (if necessary)\n",
    "# Add any preprocessing steps here, such as removing special characters, converting to lowercase, etc.\n",
    "\n",
    "# Create a Markov chain model\n",
    "import markovify\n",
    "\n",
    "text_model = markovify.Text(text_content, state_size=2) \n",
    "\n",
    "# Generate text using the model\n",
    "generated_text = text_model.make_sentence()\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada18b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nor, of those who were small enough for his sake striven all day at this place; and every day on which he sat.\n"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "\n",
    "text_model = markovify.Text(text_content, state_size=2)  # You can adjust state_size as needed\n",
    "\n",
    "# Generate text using the model\n",
    "generated_text = text_model.make_sentence()\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cae76442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a mere storm of coarse red cap.\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the model\n",
    "generated_text = text_model.make_sentence()\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5af0a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Lorry to look out at the best, on the bench on which her power had failed; but they had thrown away, and perhaps second-hand cares, like second-hand clothes, come easily off and on.\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the model\n",
    "generated_text = text_model.make_sentence()\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2288ff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Troubled as the vision of doing so.\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the model\n",
    "generated_text = text_model.make_sentence()\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38fe54e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every eye then sought some other eye in the narrow compass of one who remembered the way well, several dark and dirty street through which they tore in a cloud of great interest to whom he had no pride but in the commission of their own wills they will go there at once impressed themselves on Mr. Lorry, begged to ask him a paper through the registers on the routine of life, and the crowd waited to see it, or to the shrewd glance of Mr. Lorry.\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the model\n",
    "generated_text = text_model.make_sentence()\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Tokenize sentences in the book\n",
    "book_sentences = sent_tokenize(book_text)  # Replace book_text with the actual text of the book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc96da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who made the most remarkable goblin shadow on the general desire.\n",
      "Generated sentence is not in the book.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import markovify\n",
    "\n",
    "# Read the HTML file ( A tale of two cities )\n",
    "with open('pg98-images.html.utf8', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse HTML content and extract text\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text_content = ' '.join([p.text for p in soup.find_all('p')])  # Extract text from <p> tags, modify as needed\n",
    "\n",
    "# Create a Markov chain model\n",
    "text_model = markovify.Text(text_content, state_size=2)  # You can adjust state_size as needed\n",
    "\n",
    "# Generate text using the model\n",
    "generated_text = text_model.make_sentence()\n",
    "print(generated_text)\n",
    "\n",
    "# Read the book \"A Tale of Two Cities\" or load it from a file\n",
    "with open('pg98-images.html.utf8', 'r', encoding='utf-8') as book_file:\n",
    "    book_text = book_file.read()\n",
    "\n",
    "# Tokenize sentences in the book\n",
    "book_sentences = book_text.split('.')  # Split book text into sentences, modify as needed\n",
    "\n",
    "# Check if generated sentence is in the book\n",
    "if generated_text in book_sentences:\n",
    "    print(\"Generated sentence is identical to a sentence in the book.\")\n",
    "    print(\"Generated Sentence: \", generated_text)\n",
    "else:\n",
    "    print(\"Generated sentence is not in the book.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ba9276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated text \n",
      " (  I see the evil of this time and of the four men who had taken him last night, and Barsad.  )\n",
      "\n",
      " Generated sentence is not in the book.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import markovify\n",
    "\n",
    "# Read the HTML file ( A tale of two cities )\n",
    "with open('pg98-images.html.utf8', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse HTML content and extract text\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text_content = ' '.join([p.text for p in soup.find_all('p')])  # Extract text from <p> tags, modify as needed\n",
    "\n",
    "# Create a Markov chain model\n",
    "text_model = markovify.Text(text_content, state_size=3) \n",
    "\n",
    "# Generate text using the model\n",
    "generated_text = text_model.make_sentence()\n",
    "print(\"The generated text\",\"\\n\", \"( \", generated_text, \" )\")\n",
    "\n",
    "# Read the book \"A Tale of Two Cities\" or load it from a file\n",
    "with open('pg98-images.html.utf8', 'r', encoding='utf-8') as book_file:\n",
    "    book_text = book_file.read()\n",
    "\n",
    "# Tokenize sentences in the book\n",
    "book_sentences = book_text.split('.')  # Split book text into sentences, modify as needed\n",
    "\n",
    "# Check if generated sentence is in the book\n",
    "if generated_text in book_sentences:\n",
    "    print(\"Generated sentence is identical to a sentence in the book.\")\n",
    "    print(\"Generated Sentence: \", generated_text)\n",
    "else:\n",
    "    print(\"\\n\",\"Generated sentence is not in the book.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfe9db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
